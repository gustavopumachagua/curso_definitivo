{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 27** | **Siguiente 29** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../README.md) | [](./27_Uniform_Distribution.ipynb)| [](./29_%20Root_Mean_Square_Error.ipynb)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **28. Bagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging es una t茅cnica de ensemble que combina m煤ltiples modelos para mejorar la estabilidad y la precisi贸n del modelo final. Funciona entrenando varios modelos en conjuntos de datos de entrenamiento creados mediante bootstrap (muestreo con reemplazo), y luego agregando las predicciones de cada modelo para tomar una decisi贸n final.\n",
    "\n",
    "**Terminolog铆a:**\n",
    "\n",
    "1. **Bootstrap:** Es una t茅cnica de muestreo con reemplazo. Se crea un conjunto de datos bootstrap al seleccionar muestras del conjunto de datos de entrenamiento original de manera aleatoria y con reemplazo.\n",
    "\n",
    "2. **Ensemble:** Es la combinaci贸n de varios modelos para formar un modelo m谩s robusto y preciso.\n",
    "\n",
    "**Algoritmo Bagging:**\n",
    "\n",
    "1. **Entrenamiento:**\n",
    "   - Selecciona aleatoriamente $(K)$ conjuntos de datos bootstrap del conjunto de entrenamiento original.\n",
    "   - Entrena un modelo en cada conjunto de datos bootstrap.\n",
    "\n",
    "2. **Predicci贸n:**\n",
    "   - Realiza predicciones con cada modelo.\n",
    "   - Agrega las predicciones utilizando una estrategia de promedio o votaci贸n.\n",
    "\n",
    "**Ventajas del Bagging:**\n",
    "\n",
    "- **Reducci贸n de la Varianza:** Al entrenar modelos en conjuntos de datos diferentes, el bagging ayuda a reducir la variabilidad y el sobreajuste.\n",
    "\n",
    "- **Mayor Estabilidad:** La combinaci贸n de m煤ltiples modelos hace que el modelo final sea m谩s estable y generalizable.\n",
    "\n",
    "**F贸rmula Matem谩tica:**\n",
    "\n",
    "Supongamos que tenemos $(K)$ modelos base $(h_1, h_2, ..., h_K)$ y queremos predecir un nuevo ejemplo $(x)$. La predicci贸n del ensemble mediante bagging se realiza mediante:\n",
    "\n",
    "$\\text{Predicci贸n Final}(x) = \\frac{1}{K} \\sum_{i=1}^{K} h_i(x)$\n",
    "\n",
    "donde $h_i(x)$ es la predicci贸n del modelo base $(i)$ para el ejemplo $(x)$.\n",
    "\n",
    "**Ejemplo con Gr谩fico en Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi贸n del modelo: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generar datos de ejemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un clasificador de 谩rbol de decisi贸n\n",
    "base_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Crear el clasificador Bagging\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Bagging\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Calcular precisi贸n\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisi贸n del modelo: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo utiliza bagging con un clasificador de 谩rbol de decisi贸n base. Puedes experimentar con diferentes par谩metros, como el n煤mero de estimadores, para ver c贸mo afectan a la precisi贸n del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 27** | **Siguiente 29** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../README.md) | [](./27_Uniform_Distribution.ipynb)| [](./29_%20Root_Mean_Square_Error.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
